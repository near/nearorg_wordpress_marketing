<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>User-Owned AI Archives &#8211; NEAR Protocol</title>
	<atom:link href="/blog/tag/user-owned-ai/feed/" rel="self" type="application/rss+xml" />
	<link>/blog/tag/user-owned-ai/</link>
	<description></description>
	<lastBuildDate>Thu, 12 Sep 2024 17:48:04 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.6.1</generator>

<image>
	<url>https://pages.near.org/wp-content/uploads/2020/09/cropped-favicon-32x32.png</url>
	<title>User-Owned AI Archives &#8211; NEAR Protocol</title>
	<link>/blog/tag/user-owned-ai/</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">234542837</site>	<item>
		<title>NEAR Foundation and Delphi Labs Partner on AI x Web3 Accelerator</title>
		<link>/blog/near-foundation-and-delphi-labs-partner-on-ai-x-web3-accelerator/</link>
		
		<dc:creator><![CDATA[NEAR Team]]></dc:creator>
		<pubDate>Thu, 12 Sep 2024 16:53:43 +0000</pubDate>
				<category><![CDATA[User-Owned AI]]></category>
		<category><![CDATA[Accelerator]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[NEAR Horizon]]></category>
		<category><![CDATA[Partnerships]]></category>
		<guid isPermaLink="false">/?p=21521</guid>

					<description><![CDATA[<p>The NEAR Foundation is excited to partner with Delphi Labs to co-host a new accelerator program for high-potential projects at …</p>
<p>The post <a href="/blog/near-foundation-and-delphi-labs-partner-on-ai-x-web3-accelerator/">NEAR Foundation and Delphi Labs Partner on AI x Web3 Accelerator</a> appeared first on <a href="/">NEAR Protocol</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>The NEAR Foundation is excited to partner with Delphi Labs to co-host a new accelerator program for high-potential projects at the intersection of AI and Web3. The new cohort will launch in October and teams with a strong vision for decentralized AI applications and infrastructure are encouraged to <a href="https://www.hzn.xyz/">apply</a>.</p>



<p>Building on the success of NEAR’s first <a href="https://near.org/blog/near-foundation-launches-ai-incubation-program">AI x Web3 incubator</a>, the NEAR x Delphi Labs AI Accelerator will provide participating founders and teams with the technical, operational, and financial resources to succeed—including access to $50k in compute credits, advisory support from the NEAR co-founders, funding opportunities beginning at $100k, and token launch support.</p>



<p><a href="https://www.hzn.xyz/"><strong>Applications are open</strong></a><strong> until October 4 for teams interested in joining the accelerator</strong>, which begins on October 14.</p>



<p>NEAR Foundation and Delphi Labs share the common strategic vision of a <a href="https://near.org/blog/user-owned-ai-is-near">User-Owned AI</a> ecosystem, built on Web3 rails, that provides genuinely better alternatives to developers and users than the prevailing model of centralized AI controlled by big tech companies. The goal is to maximize the benefits of AI for people and communities—and minimize the potential risks—by putting the power of AI where it belongs: in the hands of users.&nbsp;</p>



<p>NEAR is a leading blockchain platform designed to accelerate the development of decentralized applications with a focus on usability and scalability—co-founded by Illia Polosukhin, one of the originators of the transformer architecture underpinning the present AI surge. The NEAR ecosystem vision for <a href="https://near.org/blog/user-owned-ai-is-near">User-Owned AI</a> includes building a community of aligned teams where innovations are shared openly, ensuring consistency and interoperability across projects. It also includes supporting development of the robust, open infrastructure needed to build and deploy AI applications on a decentralized network, ensuring that the future of AI is not only owned by users but is scalable, secure, and efficient for businesses and founders.</p>



<p><a href="https://delphilabs.io/">Delphi Labs</a>, a research and development firm specializing in Web3 and DeFi, brings to the accelerator a deep understanding of blockchain technology and a strong track record of supporting successful projects. </p>



<p>“Crypto x AI is the sector we’re most excited about and, given how early it is, we thought it made a lot of sense for an accelerator cohort,” explains Delphi Labs co-founder José Macedo. “NEAR is the ideal partner given that Illia is one of the original co-authors of the transformer paper and has an unparalleled understanding and network within AI.” The Delphi team’s conviction is that competitive dynamics will result in a world of millions of AI models and that Web3 is the ideal substrate for this many-model world. They are interested in finding exceptional founders who have a strong vision for how Web3 can benefit from AI, or how AI can benefit from Web3, and want to rapidly execute on this vision.</p>



<p>NEAR and Delphi are co-designing the upcoming accelerator cohort experience, slated to begin October 14 with a live kickoff gathering planned. Each participating team will receive mentorship, resources, and opportunities for investment: $100k in investment from NEAR Foundation, along with $50k in compute credits, and potential investment of up to $250k from Delphi Labs for further incubation or acceleration following the completion of the program. The program culminates mid-December at an investor-focused demo day with several top funds and angels in the space.&nbsp;</p>



<p>NEAR’s first AI x Web3 incubator cohort, which ran from June to August 2024, saw participants achieve significant early milestones while contributing essential pieces to the growing User-Owned AI stack. These milestones include: <a href="https://hyperbolic.xyz/">Hyperbolic</a> hosting the latest open source AI models, including Llama 3.1 405B; <a href="https://mizu.global/">Mizu</a> launching their beta platform and attracting 20K users in the first week; and <a href="https://cryptopond.xyz/">Pond</a> launching their first GNN model for wallet predictions and achieving a 20% prediction rate. The teams have built on the momentum from the incubator to attract serious seed funding interest, with Hyperbolic successfully closing a $7M round.</p>



<p>In addition to the NEAR x Delphi Labs AI Accelerator Program, the NEAR Foundation has also teamed up with <a href="https://www.betaworks.com/camp#about-camp">Betaworks</a> on an in-person acceleration cohort in New York City focused on consumer AI applications in the Web2 space. Running through November 2024, the Betaworks collaboration welcomes a wider roster of projects into the growing User-Owned AI ecosystem and opens further opportunities for bridging the Web3 x AI space to Web2 consumer AI.</p>



<p>To learn more about the NEAR ecosystem vision for User-Owned AI, Illia’s perspective on the intersection of AI x Web3, and the Delphi Labs team’s investment thesis in the decentralized AI space, check out <a href="https://www.youtube.com/watch?v=NgDykvSBYzo">Delphi’s new podcast episode</a>.&nbsp;</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe title="Illia Polosukhin: AI thesis, crypto x AI, and announcing the Delphi Labs x Near accelerator" width="500" height="281" src="https://www.youtube.com/embed/NgDykvSBYzo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<p><br>To follow along with the latest in the User-Owned AI ecosystem, join the NEAR.AI and HZN teams in <a href="https://lu.ma/NEAR_Token2049_SG">Singapore</a> (September) or <a href="https://redactedbangkok.ai/">Bangkok</a> (November) and tune in to <a href="https://www.youtube.com/playlist?list=PL9tzQn_TEuFWMuPiQOXhaE5lpOTnxLPZY">NEAR AI Office Hours</a> every Tuesday.</p>
<p>The post <a href="/blog/near-foundation-and-delphi-labs-partner-on-ai-x-web3-accelerator/">NEAR Foundation and Delphi Labs Partner on AI x Web3 Accelerator</a> appeared first on <a href="/">NEAR Protocol</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">21521</post-id>	</item>
		<item>
		<title>Regulation Alone Will Not Save Us from Big Tech</title>
		<link>/blog/regulation-alone-will-not-save-us-from-big-tech/</link>
		
		<dc:creator><![CDATA[Illia Polosukhin]]></dc:creator>
		<pubDate>Fri, 28 Jun 2024 18:52:39 +0000</pubDate>
				<category><![CDATA[A Post from Illia Polosukhin]]></category>
		<category><![CDATA[User-Owned AI]]></category>
		<guid isPermaLink="false">/?p=21434</guid>

					<description><![CDATA[<p>Every week, we see new headlines about lawsuits against major AI companies and infighting between regulators on how to properly …</p>
<p>The post <a href="/blog/regulation-alone-will-not-save-us-from-big-tech/">Regulation Alone Will Not Save Us from Big Tech</a> appeared first on <a href="/">NEAR Protocol</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>Every week, we see new headlines about <a href="https://www.nytimes.com/2024/06/25/arts/music/record-labels-ai-lawsuit-sony-universal-warner.html">lawsuits</a> <a href="https://www.axios.com/2024/06/18/forbes-perplexity-ai-legal-action-copyright">against</a> major AI companies and <a href="https://www.reuters.com/world/us/us-fcc-proposal-require-ai-political-ad-disclosure-draws-split-views-2024-06-06/">infighting</a> <a href="https://www.axios.com/2024/06/26/california-ai-safety-bill-industry-pushback">between</a> regulators on how to properly manage AI safety. From the notable OpenAI executive departures over the handling of safety to the whistleblower employees calling for more transparency, it’s clear that even those closest to the tech are worried about the risks that super-powerful, closed AI poses. How best can we manage this risk?&nbsp;</p>



<p><a href="https://www.wired.com/story/user-owned-ai-illia-polosukhin-open-source-web3/">I would argue</a> that regulation alone will not save us from Big Tech monopolizing Corporate-Owned AI. There is still time to make AI fair, open, and good for the world––but not a lot of time. AI must be user-owned and open source in order to be a positive force for humanity.&nbsp;</p>



<p>I am one of the co-creators of Transformers, or the “T” in ChatGPT, which we created inside one of the biggest tech companies in the world. Shortly after publishing that research, I left to found a startup and build in open source (software whose source code is open for others to read and use). While I fundamentally believe AI can improve human lives and maximize our collective intelligence, I agree that powerful AI focused on the profit of a few is risky at best and dangerous at worst.&nbsp;</p>



<p>The most prominent AI development today is happening inside of major for-profit companies. The massive economic flywheel of AI means that just a few mega-corporations will control the most advanced intelligence tooling in the world––and make decisions about it behind closed doors. The incumbents’ lead gets bigger all the time because they already have so much money for building bigger data centers, lots of available user and internet data, and established user feedback loops.&nbsp;</p>



<p>Modern tech giants are flexible to adopt new technologies at a faster pace than previous enterprises and have established frameworks for doing so. Every model optimizes for something, and every closed, for-profit company will naturally optimize for profit. In turn, the models and systems that these companies build are always optimized to maximize their own revenue, rather than any kind of success metric for the users.&nbsp;</p>



<p>The same story has played out time and time again with major tech corporations: when a user market gets so big that there aren’t as many new users to acquire, profit pressures require finding new ways to extract more money and capture more attention from each existing user. This often results in exploiting users, not because these companies or their employees are trying to be malicious but because this is how massive, closed companies are built to work.&nbsp;</p>



<p>So what can we do about this? The whistleblowers suggest that the solution is more regulation on AI, but I disagree. Often the people writing regulations don’t understand the tech well enough to keep up and so introduce requirements that are illogical or impossible to enforce. Regulation is slow and reactive rather than proactive, stifling innovation and making it harder for startups to compete and diversify the market. Regulations alone cannot control incredibly powerful and complex technology that changes faster than even its creators often realize, which too often results in asking for forgiveness after it’s already too late to prevent the negative outcome.</p>



<p>I see a more constructive solution: we need to invest in open source, <a href="https://near.org/blog/user-owned-ai-is-near">User-Owned AI</a>. Building in the open positions AI builders to collaborate on proactively managing risk, improving safety for users, and auditing and monitoring outcomes. All data that goes into training a model must be open source in order to ensure there is no malicious data, to unpack potential bias inherent to the model, and to debug issues (only sharing parameters means that malicious behavior or inherent bias can affect all subsequent applications). In corporate-owned AI, decisions about which data are and aren’t included are completely opaque to users, and that data could be (maybe already has, but I hope not) subject to prioritization of the highest bidder––we’d have no way to know for sure. Open source ensures a more diverse community of contributors and a broader base of people reviewing and testing the code and cheaply validating that models are indeed trained on a stated dataset.&nbsp;</p>



<p>User-Owned AI means intelligence tooling that optimizes for the well-being and success of individual users and their communities (rather than maximizing profit for the company building the model). Well-being and success metrics could include earning opportunities for the user, guarantees around their privacy and protection of their data and assets, and time saved. Not only can researchers and companies still make money in this paradigm by building great products that users want, but so do the users, who can selectively monetize their (provably anonymized) data or get rewarded for their attention. User-owned AI will also enhance users’ ability to customize and personalize their digital experiences, rather than the current approach where big companies deliver rigid, monolithic apps and experiences.</p>



<p>While big tech moats are hard to beat, there is an opportunity to introduce open source alternatives and better frameworks before it’s too late. The stakes are high enough to try.&nbsp;</p>



<p>–Illia Polosukhin</p>
<p>The post <a href="/blog/regulation-alone-will-not-save-us-from-big-tech/">Regulation Alone Will Not Save Us from Big Tech</a> appeared first on <a href="/">NEAR Protocol</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">21434</post-id>	</item>
		<item>
		<title>Self-Sovereignty Is NEAR: A Vision for Our Ecosystem</title>
		<link>/blog/self-sovereignty-is-near-a-vision-for-our-ecosystem/</link>
		
		<dc:creator><![CDATA[Illia Polosukhin]]></dc:creator>
		<pubDate>Fri, 19 Jan 2024 20:19:02 +0000</pubDate>
				<category><![CDATA[A Post from Illia Polosukhin]]></category>
		<category><![CDATA[Chain Abstraction]]></category>
		<category><![CDATA[Mission & vision]]></category>
		<category><![CDATA[NEAR Ecosystem]]></category>
		<category><![CDATA[Self-Sovereignty]]></category>
		<category><![CDATA[User-Owned AI]]></category>
		<guid isPermaLink="false">/?p=21170</guid>

					<description><![CDATA[<p>As a kid growing up in Ukraine in the ’90s after the dissolution of the USSR, I remember we watched …</p>
<p>The post <a href="/blog/self-sovereignty-is-near-a-vision-for-our-ecosystem/">Self-Sovereignty Is NEAR: A Vision for Our Ecosystem</a> appeared first on <a href="/">NEAR Protocol</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p></p>



<p>As a kid growing up in Ukraine in the ’90s after the dissolution of the USSR, I remember we watched the price of bread go from 1,000 karbovanets, to 10,000, to 100,000 in less than five years (until that currency was thrown out altogether and replaced with hryvnia). When I first started working as a software developer as a teenager, I kept my earnings in cash in my room because I already understood that we couldn’t trust corrupt banks with our money.</p>



<p>Between 2014 and 2016 alone, 77 banks failed in Ukraine. My grandparents still have their savings account bank books tracking the money they put away during the USSR years––but those savings don’t exist anymore. So even something that is yours, that you rightfully own, can go away if the system you’re a part of fails. The same thing is happening to millions of people living under hyperinflation, dictatorships, and war zones across the world, of course. And while these may seem like abstract or distant problems that won’t arrive at your doorstep, let me tell you from my own experience: nothing is guaranteed.&nbsp;</p>



<p>Every system is as fragile as the rules holding it together. And the rules can change. They’re changing around us right now, and I believe we are approaching a point of no return.&nbsp;</p>



<p><strong>The Need for Digital Self-Sovereignty</strong></p>



<p>We need to create new economic opportunities for people everywhere via self-sovereignty, which should be a universal right and which technology can now provide, not just nation-states as in most other points in history. For citizens of nations who’ve enjoyed economic security and a high degree of sovereignty, this may not seem like an immediate-term issue. But it is.&nbsp;</p>



<p>The economics of tech companies leads inevitably to corrupting their original product or vision for the sake of profit in order to maintain growth, and more importantly, they naturally involve creating barriers for someone else to disrupt. In order to maintain their power, governments will use pressure and ingenuity in order to control their populations, too often to the point of violating human rights in the name of safety or security.&nbsp;</p>



<p>We all use our phones and computers a thousand times a day, prioritizing convenience over self-sovereignty because <em>until now, we haven’t had a choice</em>. We are now approaching a tipping point towards a dystopian future that we may not be able to come back from, brought on not just by governments but by the economics of tech companies. What happens when these incentives increasingly collide and push each other deeper into the lives of individuals for the sake of maintaining control and profit?&nbsp;</p>



<p>That’s right about where we are today.&nbsp;</p>



<p><strong>Changing the Stakes with Generative AI</strong></p>



<p>Before founding NEAR, I was an AI researcher. I worked at Google where I contributed to TensorFlow, and eventually published a paper with a handful of colleagues called “Attention Is All You Need.” That paper introduced the Transformers architecture that powers ChatGPT, Bard, and most of the well-known LLMs behind last year’s explosive growth in AI.&nbsp;</p>



<p>I was first interested in AI because of the 2001 movie, “Artificial Intelligence.” Changing how we interact with computing and augmenting one&#8217;s intelligence to maximize human potential was, and still is, very appealing to me. And I still think it has the potential to make human lives, organizations, even governments better. But like any other technology, in the hands of the wrong people or with the wrong incentives, it also has the potential to make our lives terrible. </p>



<p>Generative AI is creating a universal and scalably personal method of enabling control and manipulation. Practically, it means your social feed and search results can ensure that you buy specific products or form a specific opinion. This will start in the form of commercial improvements that lead to more profit for tech giants: Netflix will generate a movie script that can shape your opinion, Facebook can reinforce that opinion by showing you more of it, and so on. This could even happen at a more fundamental level, such as flooding training data with specific information to influence all models trained on it.&nbsp;</p>



<p>If this granular information and vector of manipulation on such a personal level can be extracted or bought, it will be, and then it will become a tool for control. If it’s stored somewhere centralized and hackable, it will be stolen––we see this constantly with Web2 giants as it is. If governments can get access to this data, they will use it to maintain or grow their power.&nbsp;</p>



<p>The true danger that generative AI introduces is that this exploitation won’t just be on a systems level or a population level, it will become personal and incredibly specific. The depth of potential control and manipulation goes to the level of each and every human, no matter where they live, no matter where they keep their money. Such a powerful technology simply cannot remain in the hands of centralized companies, nor be too easy for governments to take over.</p>



<p><strong>So What Should We Do About It?</strong></p>



<p>So if people don’t yet feel the sense of urgency towards building new systems that uphold self-sovereignty, what will make it real for people? Changes in collective values are always driven by economic opportunity. The major revolutions of history started because of economic failures: American independence from Britain, the French Revolution, the collapse of the USSR, and so on. If people see ways to create better economic realities for themselves and their families, then they will turn values into actions.&nbsp;</p>



<p>Creating new opportunities for people via self-sovereignty is what NEAR is about. Complete self-sovereignty&nbsp; has been the NEAR vision since day one: we want to build a world where all people can control their own assets, data, and power of governance. This sovereignty must apply not only at the level of individuals but also the organizations and communities they create, and eventually societies.&nbsp;</p>



<p>Self-sovereignty is a new primitive that hasn’t existed before today. One always needed to rely on some power of violence for ensuring rules are followed, most recently nation-states. One of the core principles of digital self-sovereignty is the ability to choose and switch between any service provider. There is no lock- in. There are no middlemen like banks or government agencies that can lose or steal assets, or change the rules on you out of nowhere.&nbsp;</p>



<p>Importantly, this must also apply to AI. People need to own their data so they know what it’s being used for and so they can actively consent to personalized experiences they think will improve their lives. Models must be governed transparently, in public, with clear rules and monitoring to proactively manage risk and reputation systems to build more clarity around information and traceability. Web3 can help to uphold, scale, and manage such systems to ensure AI is a force for good while also preventing it from being too exploitable.&nbsp;</p>



<p>Another major challenge, which is especially clear in governance but it also applies to corporations, is that when we select someone to represent our ideas for us as our delegate, they will always have their own interests and motivations in the mix as well. They don’t necessarily have nefarious intentions, it’s just a natural tendency. This is the “principal agent problem,” wherein the person elected behaves differently than the people who elected them or pay them would prefer based on their best interests. This is where AI governance systems can help by introducing neutral agents, where unbiased AI agents governed directly by a community can act on their behalf in a more reliable way. With transparent governance and monitoring, AI can be a force for good in individual lives as well as for the collective.&nbsp;</p>



<p><strong>A Vision for the NEAR Future</strong></p>



<p>Despite my concerns about where the traditional tech paradigm is potentially heading, I remain a techno-optimist. I wouldn’t be doing this work if I didn’t think it was for the good of everyone, and I’ve read enough sci-fi to know that the outcomes of science and technology are much more about what people do with them than the tech itself. If we want something, we should build it.&nbsp;</p>



<p>I would like NEAR to become a fully sovereign operating system that is equipped with a personal AI assistant that optimizes for users’ needs without revealing private information about the user’s data or assets. It should also be able to interact and transact with other people’s AIs and the community’s AIs peer-to-peer. I call this “user-owned AI.”</p>



<p>We also need shared community AIs, which are governed by the members of such a community. They represent the mix of needs and knowledge of all the members of such a community, from something like a small club or startup, to the city, to the nation-state, to the global level. There is always an opportunity to fork one community and create new ones. The community governs which data goes into training its community model, and can run inference (running live data through a model) privately in such a way that only the user sees input and output, while getting a proof that the selected model was used.</p>



<p>To facilitate this vision, a lot of pieces need to come together:</p>



<ul class="wp-block-list">
<li>Economic and technological opportunity to enable users to onboard en masse.</li>



<li>Open source software across the stack, from blockchain tech to AI models.</li>



<li>Blockchains must get abstracted away from the user so they are not barriers to entry or participation. I call this the principle of Chain Abstraction.</li>



<li>Applications must provide a novel value unlock: for example, <a href="https://kaikai.ai/">Cosmose</a> and <a href="https://sweateconomy.com/">Sweat</a>. These apps reward users and serve as an economic gateway into a broader ecosystem of opportunities.</li>



<li>On-edge, meaning hyperlocal, AI models that are usable by individuals (and free of manipulation).</li>



<li>Community-owned AI models with governance and economic opportunity, replacing everything from business ops to government agencies. Self-governance by the people, for the people, at scale with the help of technology and decentralized peer-to-peer systems.</li>
</ul>



<p>Blockchains, peer-to-peer payments, Web3, zero-knowledge, very large language models and on-edge AI models: these are not separate technology verticals, but rather interconnected facets of a new digital paradigm of self-sovereignty.&nbsp;</p>



<p>We have the tools to remake how we provide for ourselves, how we work together and govern ourselves, and how we consume and generate information. Without gatekeepers, fair and open to everyone. And this is not a futuristic vision: it’s possible to start experimenting and building now, before our fragile and outdated systems and structures get weaker or fail, before too much centralization leads to the worst outcomes instead of the ones we all design and share together.<br><br>––<em>Illia Polosukhin, Co-Founder of NEAR and CEO of NEAR Foundation</em></p>
<p>The post <a href="/blog/self-sovereignty-is-near-a-vision-for-our-ecosystem/">Self-Sovereignty Is NEAR: A Vision for Our Ecosystem</a> appeared first on <a href="/">NEAR Protocol</a>.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">21170</post-id>	</item>
	</channel>
</rss>
